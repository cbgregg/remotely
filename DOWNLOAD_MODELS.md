# üöÄ Download Large Language Models

Your LLM Chat App now supports powerful models from 1.1B to 32B parameters! Here's how to download them:

## üìã Available Models

### üèÉ‚Äç‚ôÇÔ∏è **Fast Models (Good for testing)**
- **TinyLlama 1.1B** - Already included
- **Phi-3 Mini 3.8B** - Already included

### üß† **High-Quality Models (Recommended)**

#### **Llama 3.2 3B (Good)**
```bash
# Download (1.9GB)
curl -L -o llama-3.2-3b-instruct-q4_k_m.gguf \
  "https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q4_K_M.gguf"
```

#### **Qwen 2.5 7B (Great)**
```bash
# Download (4.1GB)
curl -L -o qwen2.5-7b-instruct-q4_k_m.gguf \
  "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct-GGUF/resolve/main/qwen2.5-7b-instruct-q4_k_m.gguf"
```

#### **Llama 3.1 8B (Superior)**
```bash
# Download (4.6GB)
curl -L -o llama-3.1-8b-instruct-q4_k_m.gguf \
  "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf"
```

### üèÜ **Premium Models (Best Quality)**

#### **Mistral Nemo 12B (Premium)**
```bash
# Download (6.8GB)
curl -L -o mistral-nemo-12b-instruct-2407-q4_k_m.gguf \
  "https://huggingface.co/bartowski/Mistral-Nemo-Instruct-2407-GGUF/resolve/main/Mistral-Nemo-Instruct-2407-Q4_K_M.gguf"
```

#### **Qwen 2.5 14B (Outstanding)**
```bash
# Download (8.3GB)
curl -L -o qwen2.5-14b-instruct-q4_k_m.gguf \
  "https://huggingface.co/Qwen/Qwen2.5-14B-Instruct-GGUF/resolve/main/qwen2.5-14b-instruct-q4_k_m.gguf"
```

#### **Qwen 2.5 32B (Ultimate)**
```bash
# Download (18.8GB - Requires 32GB+ RAM)
curl -L -o qwen2.5-32b-instruct-q4_k_m.gguf \
  "https://huggingface.co/Qwen/Qwen2.5-32B-Instruct-GGUF/resolve/main/qwen2.5-32b-instruct-q4_k_m.gguf"
```

## üìÅ Installation Instructions

### **Method 1: Direct Download (Recommended)**
1. Open Terminal
2. Navigate to your project directory:
   ```bash
   cd "/Users/cartergregg/Documents/cursor project 3/LLMtest"
   ```
3. Run the download command for your chosen model
4. The model will be automatically added to your app bundle on next build

### **Method 2: Manual Download**
1. Click the download links above in your browser
2. Save the `.gguf` file to your project directory
3. In Xcode, drag the file into your project
4. Make sure "Copy Bundle Resources" is checked

## üíæ System Requirements

| Model Size | RAM Required | Download Size | Quality Level |
|------------|-------------|---------------|---------------|
| 1.1B | 4GB+ | 700MB | Basic |
| 3.8B | 8GB+ | 2.3GB | Good |
| 3B | 8GB+ | 1.9GB | Good |
| 7B | 12GB+ | 4.1GB | Great |
| 8B | 16GB+ | 4.6GB | Superior |
| 12B | 20GB+ | 6.8GB | Premium |
| 14B | 24GB+ | 8.3GB | Outstanding |
| 32B | 32GB+ | 18.8GB | Ultimate |

## üéØ Model Recommendations

### **For Most Users: Qwen 2.5 7B**
- Excellent balance of quality and performance
- 32K context window (huge!)
- Great for coding, writing, and analysis
- Works well on 16GB+ RAM systems

### **For Power Users: Llama 3.1 8B**
- Meta's latest and greatest
- Massive 32K context window
- Excellent reasoning capabilities
- Industry standard model

### **For Maximum Quality: Qwen 2.5 32B**
- Near GPT-4 level performance
- Best reasoning and knowledge
- Requires high-end hardware
- Professional-grade results

## üîß Performance Tips

1. **Start Small**: Try 7B models first, then upgrade
2. **Monitor RAM**: Check Activity Monitor while running
3. **Close Other Apps**: Free up memory for better performance
4. **Use SSD**: Store models on fast storage for quick loading
5. **Enable GPU**: Models automatically use Metal acceleration

## üåê Web Search + Large Models = üî•

These larger models combined with web search create an incredibly powerful AI assistant:

- **Real-time Information**: Web search provides current data
- **Deep Understanding**: Large models provide sophisticated reasoning
- **Accurate Responses**: Anti-hallucination features ensure reliability
- **Long Conversations**: 32K context windows remember everything

## üö® Important Notes

- **First Run**: Models take longer to load initially
- **Memory Usage**: Monitor system performance
- **Model Updates**: Check for newer versions periodically
- **Backup**: Keep your conversation exports safe

## üéâ Enjoy Your Powerful AI Assistant!

With these models, you now have access to some of the most capable open-source AI available, running completely locally on your Mac! 